{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pokemon.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WadeChao1011/Pokemon/blob/master/Pokemon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QABE_ICSIZfc",
        "colab_type": "text"
      },
      "source": [
        "Pokemon Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5nc4vFQWabK",
        "colab_type": "text"
      },
      "source": [
        "!mkdir 建立資料夾用來存圖片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8e5FrxcgQQC",
        "colab_type": "code",
        "outputId": "4e08c72d-1d18-47eb-fe42-887c87a6b993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir dataset/Gengar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘dataset/Gengar’: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHJJYkyJWYBh",
        "colab_type": "text"
      },
      "source": [
        "安裝request包處理導入此腳本所需的包。之後創建Python腳本以下載圖像循環當前批量的圖像，並"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZSChfKpCUjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install requests\n",
        "from requests import exceptions\n",
        "import requests\n",
        "import cv2\n",
        "import os\n",
        "import gevent\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVxJCzvfD19j",
        "colab_type": "text"
      },
      "source": [
        "註冊Bing Image Search API獲取API金鑰，用MAX_RESULTS   和 GROUP_SIZE   以進行搜索，GROUP_SIZE   參數可視為要返回“每頁”的搜索結果數。因此，如果我們想要總共250個圖像，我們需要通過5個“頁面”，每頁50個圖像。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3ASBQevCizq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# poke name to download\n",
        "pokemon = 'Gengar'\n",
        "output = 'dataset/Gengar'\n",
        "\n",
        "API_KEY = \"AIzaSyDiWUj7RLWrl_JfUdZtbeRaHfDuugw6IWA\"\n",
        "MAX_RESULTS = 250\n",
        "GROUP_SIZE = 50\n",
        " \n",
        "# set the endpoint API URL\n",
        "URL = \"https://api.cognitive.microsoft.com/bing/v7.0/images/search\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui3TJ_ccEPgY",
        "colab_type": "text"
      },
      "source": [
        "接下列出可能遇到的異常，試著捕捉它們並在以後處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhseVdHBCoRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# when attempting to download images from the web both the Python\n",
        "# programming language and the requests library have a number of\n",
        "# exceptions that can be thrown so let's build a list of them now\n",
        "# so we can filter on them\n",
        "EXCEPTIONS = {IOError, FileNotFoundError, exceptions.RequestException, exceptions.HTTPError, exceptions.ConnectionError,\n",
        "              exceptions.Timeout}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "771nJBAzEkWf",
        "colab_type": "text"
      },
      "source": [
        "開始執行搜索並以JSON格式獲取結果，計算並向終端打印估計的結果數量，為了保留圖像的計數器將其初始化。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AxPAtR-C1Xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# store the search term in a convenience variable then set the\n",
        "# headers and search parameters\n",
        "term = pokemon\n",
        "headers = {\"Ocp-Apim-Subscription-Key\": API_KEY}\n",
        "params = {\"q\": term, \"offset\": 0, \"count\": GROUP_SIZE}\n",
        "\n",
        "# make the search\n",
        "print(\"[INFO] searching Bing API for '{}'\".format(term))\n",
        "search = requests.get(URL, headers=headers, params=params)\n",
        "search.raise_for_status()\n",
        "\n",
        "# grab the results from the search, including the total number of\n",
        "# estimated results returned by the Bing API\n",
        "results = search.json()\n",
        "estNumResults = min(results[\"totalEstimatedMatches\"], MAX_RESULTS)\n",
        "print(\"[INFO] {} total results for '{}'\".format(estNumResults, term))\n",
        "\n",
        "# initialize the total number of images downloaded thus far\n",
        "total = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi4zvR1qEtzC",
        "colab_type": "text"
      },
      "source": [
        "嘗試將每個單獨的圖像下載到輸出文件夾。建立一個try-catch塊，以便可以捕獲之前在腳本中定義的可能EXCEPTIONS，如果遇到異常，將跳過該特定圖像並向前移動。在try塊內部 我們嘗試通過URL獲取圖像，並為其構建路徑+文件名。只要 圖像數據不是None  ，我們就會更新我們的總計數器並循環回到頂部。否則，我們稱 os 。刪除以刪除無效圖像，我們繼續回到循環的頂部而不更新我們的計數器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71-l95dQhQdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def grab_page(url, ext, total):\n",
        "\n",
        "    try:\n",
        "        # total += 1\n",
        "        print(\"[INFO] fetching: {}\".format(url))\n",
        "        r = requests.get(url, timeout=30)\n",
        "        # build the path to the output image\n",
        "\n",
        "        #here total is only for filename creation\n",
        "        p = os.path.sep.join([output, \"{}{}\".format(\n",
        "            str(total).zfill(8), ext)])\n",
        "\n",
        "        # write the image to disk\n",
        "        f = open(p, \"wb\")\n",
        "        f.write(r.content)\n",
        "        f.close()\n",
        "\n",
        "        # try to load the image from disk\n",
        "        image = cv2.imread(p)\n",
        "\n",
        "        # if the image is None then we could not properly load the\n",
        "        # image from disk (so it should be ignored)\n",
        "        if image is None:\n",
        "            print(\"[INFO] deleting: {}\".format(p))\n",
        "            os.remove(p)\n",
        "            return\n",
        "\n",
        "    # catch any errors that would not unable us to download the\n",
        "    # image\n",
        "    except Exception as e:\n",
        "        # check to see if our exception is in our list of\n",
        "        # exceptions to check for\n",
        "        if type(e) in EXCEPTIONS:\n",
        "            print(\"[INFO] skipping: {}\".format(url))\n",
        "            return\n",
        "\n",
        "# loop over the estimated number of results in GROUP_SIZE groups\n",
        "for offset in range(0, estNumResults, GROUP_SIZE):\n",
        "    # update the search parameters using the current offset, then\n",
        "    # make the request to fetch the results\n",
        "    print(\"[INFO] making request for group {}-{} of {}...\".format(\n",
        "        offset, offset + GROUP_SIZE, estNumResults))\n",
        "    params[\"offset\"] = offset\n",
        "    search = requests.get(URL, headers=headers, params=params)\n",
        "    search.raise_for_status()\n",
        "    results = search.json()\n",
        "    print(\"[INFO] saving images for group {}-{} of {}...\".format(\n",
        "        offset, offset + GROUP_SIZE, estNumResults))\n",
        "    # loop over the results\n",
        "    jobs = []\n",
        "    for v in results[\"value\"]:\n",
        "        total += 1\n",
        "        ext = v[\"contentUrl\"][v[\"contentUrl\"].rfind(\".\"):]\n",
        "        url = v[\"contentUrl\"]\n",
        "        \n",
        "        # create gevent job\n",
        "        jobs.append(gevent.spawn(grab_page, url, ext, total))\n",
        "\n",
        "    # wait for all jobs to complete\n",
        "    gevent.joinall(jobs, timeout=10)\n",
        "    print(total)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHKm6GqO7Uic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir dataset/Arceus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjPTtxlI6Zsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install requests\n",
        "from requests import exceptions\n",
        "import requests\n",
        "import cv2\n",
        "import os\n",
        "import gevent\n",
        "\n",
        "# poke name to download\n",
        "pokemon = 'Arceus'\n",
        "output = 'dataset/Arceus'\n",
        "\n",
        "API_KEY = \"3fa3101e0cb4473e8ad7a66ca86f9321\"\n",
        "MAX_RESULTS = 250\n",
        "GROUP_SIZE = 50\n",
        " \n",
        "# set the endpoint API URL\n",
        "URL = \"https://api.cognitive.microsoft.com/bing/v7.0/images/search\"\n",
        "\n",
        "# when attempting to download images from the web both the Python\n",
        "# programming language and the requests library have a number of\n",
        "# exceptions that can be thrown so let's build a list of them now\n",
        "# so we can filter on them\n",
        "EXCEPTIONS = {IOError, FileNotFoundError, exceptions.RequestException, exceptions.HTTPError, exceptions.ConnectionError,\n",
        "              exceptions.Timeout}\n",
        "\n",
        "# store the search term in a convenience variable then set the\n",
        "# headers and search parameters\n",
        "term = pokemon\n",
        "headers = {\"Ocp-Apim-Subscription-Key\": API_KEY}\n",
        "params = {\"q\": term, \"offset\": 0, \"count\": GROUP_SIZE}\n",
        "\n",
        "# make the search\n",
        "print(\"[INFO] searching Bing API for '{}'\".format(term))\n",
        "search = requests.get(URL, headers=headers, params=params)\n",
        "search.raise_for_status()\n",
        "\n",
        "# grab the results from the search, including the total number of\n",
        "# estimated results returned by the Bing API\n",
        "results = search.json()\n",
        "estNumResults = min(results[\"totalEstimatedMatches\"], MAX_RESULTS)\n",
        "print(\"[INFO] {} total results for '{}'\".format(estNumResults, term))\n",
        "\n",
        "# initialize the total number of images downloaded thus far\n",
        "total = 0\n",
        "\n",
        "\n",
        "def grab_page(url, ext, total):\n",
        "\n",
        "    try:\n",
        "        # total += 1\n",
        "        print(\"[INFO] fetching: {}\".format(url))\n",
        "        r = requests.get(url, timeout=30)\n",
        "        # build the path to the output image\n",
        "\n",
        "        #here total is only for filename creation\n",
        "        p = os.path.sep.join([output, \"{}{}\".format(\n",
        "            str(total).zfill(8), ext)])\n",
        "\n",
        "        # write the image to disk\n",
        "        f = open(p, \"wb\")\n",
        "        f.write(r.content)\n",
        "        f.close()\n",
        "\n",
        "        # try to load the image from disk\n",
        "        image = cv2.imread(p)\n",
        "\n",
        "        # if the image is None then we could not properly load the\n",
        "        # image from disk (so it should be ignored)\n",
        "        if image is None:\n",
        "            print(\"[INFO] deleting: {}\".format(p))\n",
        "            os.remove(p)\n",
        "            return\n",
        "\n",
        "    # catch any errors that would not unable us to download the\n",
        "    # image\n",
        "    except Exception as e:\n",
        "        # check to see if our exception is in our list of\n",
        "        # exceptions to check for\n",
        "        if type(e) in EXCEPTIONS:\n",
        "            print(\"[INFO] skipping: {}\".format(url))\n",
        "            return\n",
        "\n",
        "# loop over the estimated number of results in GROUP_SIZE groups\n",
        "for offset in range(0, estNumResults, GROUP_SIZE):\n",
        "    # update the search parameters using the current offset, then\n",
        "    # make the request to fetch the results\n",
        "    print(\"[INFO] making request for group {}-{} of {}...\".format(\n",
        "        offset, offset + GROUP_SIZE, estNumResults))\n",
        "    params[\"offset\"] = offset\n",
        "    search = requests.get(URL, headers=headers, params=params)\n",
        "    search.raise_for_status()\n",
        "    results = search.json()\n",
        "    print(\"[INFO] saving images for group {}-{} of {}...\".format(\n",
        "        offset, offset + GROUP_SIZE, estNumResults))\n",
        "    # loop over the results\n",
        "    jobs = []\n",
        "    for v in results[\"value\"]:\n",
        "        total += 1\n",
        "        ext = v[\"contentUrl\"][v[\"contentUrl\"].rfind(\".\"):]\n",
        "        url = v[\"contentUrl\"]\n",
        "        \n",
        "        # create gevent job\n",
        "        jobs.append(gevent.spawn(grab_page, url, ext, total))\n",
        "\n",
        "    # wait for all jobs to complete\n",
        "    gevent.joinall(jobs, timeout=10)\n",
        "    print(total)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCsXMdFpFcm7",
        "colab_type": "text"
      },
      "source": [
        "導入模塊 - 注意它們都來自Keras。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggWM_gv7Ufh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIhRxA_EUiWL",
        "colab_type": "text"
      },
      "source": [
        "定義 SmallerVGGNet。\n",
        "構建方法需要四個參數：\n",
        "width  ：圖像寬度尺寸。\n",
        "height  ：圖像高度尺寸。\n",
        "深度  ：圖像的深度 - 也稱為通道數。\n",
        "classes  ：數據集中的類數（將影響模型的最後一層）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgdAle7rVCek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SmallerVGGNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\" and the channels dimension itself\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        " \n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\t# and channels dimension\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\t\t\tchanDim = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rlm_-9DVGQr",
        "colab_type": "text"
      },
      "source": [
        "開始向模型添加圖層。第一個  CONV = > RELU = > POOL   塊。卷積層具有 32個濾波器和 3 × 3內核。我們使用 RELU 激活函數，然後進行批量標準化。我們的 POOL  層使用 3 x 3 POOL 大小將空間尺寸從96 x 96 快速縮小到 32 x 32   。從代碼塊中可以看出，我們還將在網絡架構中使用dropout。Dropout通過將節點從當前層隨機斷開連接到下一層來工作。在訓練批次期間隨機斷開連接的過程有助於自然地在模型中引入冗餘 - 層中沒有一個單個節點負責預測某個類，對象，邊緣或角落。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS3LfTS2V7wZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # CONV => RELU => POOL\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\t\tmodel.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4o4LRpVWASU",
        "colab_type": "text"
      },
      "source": [
        "在應用另一個POOL層之前 添加 (CONV = > RELU ）* 2 層。將多個CONV  和 RELU  層堆疊 在一起（在減小卷的空間維度之前）允許學習更豐富的一組功能。將過濾器大小從 32  增加到 64  。在網絡中越深入，音量空間尺寸就越小，學到的濾波器就越多。將最大池大小從3 x 3 減小   到 2 x 2，以確保我們不會過快地減小空間尺寸。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY00ZGWOXDK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # (CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMalZTuqXOF2",
        "colab_type": "text"
      },
      "source": [
        " 此處將過濾器大小增加到 128。執行25％節點的丟失以再次減少過度擬合。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZBL3DxbXU5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # (CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3K1d9weXt2r",
        "colab_type": "text"
      },
      "source": [
        "最後有一組 FC = > RELU   層和一個softmax分類器。完全連接的層由Dense （1024 ）指定， 具有經過整流的線性單元激活和批量歸一化。輟學是在最後一次進行的 - 這次注意到在訓練期間輟學了50％的節點。通常情況下，在完全連接的層中使用40-50％的丟失率，並且使用率較低的丟失率，通常在之前的層中為10-25％（如果有任何丟失的話）。使用softmax分類器完善模型，該分類器將返回每個類標籤的預測概率。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgWNgdi1hHMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(1024))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        " \n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        " \n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsxLn_F4aYSM",
        "colab_type": "text"
      },
      "source": [
        "使用 “Agg”   matplotlib後端，以便可以在後台保存數字。 ImageDataGenerator   類將被用於數據擴張，用於拍攝在數據集中現有圖像和應用隨機變換（旋轉，剪切等），以產生額外的訓練數據的技術。數據增強有助於防止過度擬合。導入 Adam 優化器，這是用於訓練網絡的優化器方法。LabelBinarizer 是需要注意的一個重要的類，這個類將使我們能夠：\n",
        "1.輸入一組類標籤（即表示我們數據集中人類可讀類標籤的字符串）。\n",
        "2.將我們的類標籤轉換為單熱編碼向量。\n",
        "3.允許我們從Keras CNN獲取整數類標籤預測，並將其轉換回人類可讀的標籤。 \n",
        "train_test_split   功能將被用於創建培訓和測試分裂。\n",
        "SmallerVGGNet導入，這是剛剛在上一節中實現的Keras CNN。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9Ou-oOWaU3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        " \n",
        "# import the necessary packages\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from pyimagesearch.smallervggnet import SmallerVGGNet\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import pickle \n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6vDTsW2bzxs",
        "colab_type": "text"
      },
      "source": [
        "訓練腳本，我們需要提供三個必需的命令行參數：\n",
        "\n",
        "- dataset  ：輸入數據集的路徑。我們的數據集組織在一個 數據集   目錄中，子目錄代表每個類。每個子目錄裡面都有~250個口袋妖怪圖像。有關更多詳細信息，請參閱本文頂部的項目目錄結構。\n",
        "- model  ：輸出模型的路徑 - 此訓練腳本將訓練模型並將其輸出到磁盤。\n",
        "- labelbin  ：輸出標籤二進製文件的路徑 - 正如您稍後將看到的，我們將從數據集目錄名稱中提取類標籤並構建標籤二進製文件。\n",
        "我們還有一個可選參數 - plot  。如果未指定路徑/文件名， 則為繪圖。png   文件將放在當前工作目錄中。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRjUFJ6lby3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install --upgrade imutils\n",
        "# construct the argument parse and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-d\", \"- -dataset\", required=True,\n",
        "\t#help=\"path to input dataset (i.e., directory of images)\")\n",
        "#ap.add_argument(\"-m\", \"- -model\", required=True,\n",
        "\t#help=\"path to output model\")\n",
        "#ap.add_argument(\"-l\", \"- -labelbin\", required=True,\n",
        "\t#help=\"path to output label binarizer\")\n",
        "#ap.add_argument(\"-p\", \"- -plot\", type=str, default=\"plot.png\",\n",
        "\t#help=\"path to output accuracy/loss plot\")\n",
        "#args = vars(ap.parse_args())\n",
        "dataset='dataset'\n",
        "modelz='pokedex.model'\n",
        "labelbin='lb.pickle'\n",
        "plot='plot.png'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "werzwkWnhWg2",
        "colab_type": "text"
      },
      "source": [
        "處理完命令行參數，那麼開始初始化一些重要的變量。\n",
        "初始化訓練Keras CNN時使用的重要變量：\n",
        "EPOCHS :訓練網絡的時代總數。\n",
        "INIT_LR :初始學習速率 - 值1e-3是Adam優化器的默認值，使用優化器來訓練網絡。\n",
        "BS :將批量圖像傳遞到網絡進行培訓。每個時期有多個批次。所述 BS值控制批量大小。\n",
        "IMAGE_DIMS :這裡提供輸入圖像的空間維度。要求輸入圖像為 96 x 96 像素，有3個通道（即RGB)。還要注意，專門為SmallerVGGNet設計了 96 x 96  圖像。數據 標籤將舉行的預處理的圖像和標籤，分別抓住所有圖像路徑並隨機地移動它們。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCmNsp5tipBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the number of epochs to train for, initial learning rate,\n",
        "# batch size, and image dimensions\n",
        "EPOCHS = 100\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "IMAGE_DIMS = (96, 96, 3)\n",
        " \n",
        "# initialize the data and labels\n",
        "data = []\n",
        "labels = []\n",
        " \n",
        "# grab the image paths and randomly shuffle them\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = sorted(list(paths.list_images(dataset)))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YST3dOV8iuvq",
        "colab_type": "text"
      },
      "source": [
        "遍歷所有的 imagePaths上，然後進行加載圖像，並調整其大小，以適應模型。更新數據和標籤列表，調用 Keras img_to_array   函數將圖像轉換為Keras兼容數組，然後將圖像附加到名為 data的數據列 。對於標籤 列表，從文件路徑中  提取 標籤，並將其（標籤）附加"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8JNpo2soIet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loop over the input images\n",
        "for imagePath in imagePaths:\n",
        "\t# load the image, pre-process it, and store it in the data list\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "\timage = img_to_array(image)\n",
        "\tdata.append(image)\n",
        " \n",
        "\t# extract the class label from the image path and update the\n",
        "\t# labels list\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\tlabels.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG4H7o95oPmt",
        "colab_type": "text"
      },
      "source": [
        "第一次的轉換數據陣列為NumPy的數組，然後縮放像素強度的範圍[0，1]。我們還將標籤從列表轉換為NumPy數組  。打印信息消息，顯示數據矩陣的大小（以MB為單位） 。然後，使用scikit-learn的LabelBinarizer對標籤進行二值化 。通過深入學習或任何機器學習，通常的做法是進行培訓和測試分離。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96y_84kHoy_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scale the raw pixel intensities to the range [0, 1]\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)\n",
        "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
        "\tdata.nbytes / (1024 * 1000.0)))\n",
        " \n",
        "# binarize the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        " \n",
        "# partition the data into training and testing splits using 80% of\n",
        "# the data for training and the remaining 20% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,\n",
        "\tlabels, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijYZa0C4o05z",
        "colab_type": "text"
      },
      "source": [
        "接下來，創建圖像數據增強對象。由於正在使用有限數量的數據點（每個類別<250個圖像），可以在訓練過程中利用數據增強來為模型提供更多圖像（基於現有圖像）進行訓練。初始化了 ImageDataGenerator。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEuiBE1cpMX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
        "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEvi7Mv4peba",
        "colab_type": "text"
      },
      "source": [
        "編譯模型並啟動培訓。使用具有學習率衰減的 Adam優化器，然後使用分類交叉熵編譯模型，因為有> 2個類。調用 Keras fit_generator 方法來訓練網絡。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl7RpfbQp5Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
        "\tdepth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        " \n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
        "        validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
        "        epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4tUJO1Sqi6V",
        "colab_type": "text"
      },
      "source": [
        "序列化模型和標籤二進制化器，以便稍後在classify .py  腳本中輕鬆使用它們 。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtiBPVhNqdwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to disk\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save(dataset(modelz))\n",
        "\n",
        "# save the label binarizer to disk\n",
        "print(\"[INFO] serializing label binarizer...\")\n",
        "f = open(dataset(labelbin), \"wb\")\n",
        "f.write(pickle.dumps(lb))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02yvROaOm0lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "N = EPOCHS\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.savefig(dataset(plot))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}